{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "rYwTJGOxMUxE",
    "outputId": "21f0eddc-092c-4953-cd88-c13529d4601f"
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/jainkrunal/HandGestureRecognition\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KhziSnJPMuG2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-aa73ca820cc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from skimage import transform\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory, d)\n",
    "        file_names = [os.path.join(label_directory, f) for f in os.listdir(label_directory)]\n",
    "        for f in file_names:\n",
    "            images.append(data.imread(f))\n",
    "            labels.append(ord(d))\n",
    "    return images, labels\n",
    "\n",
    "ROOT_PATH=\"HandGestureRecognition/Data\"\n",
    "train_data_directory=os.path.join(ROOT_PATH, \"train\")\n",
    "\n",
    "images, labels=load_data(train_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UT_xqT_jOn-i"
   },
   "outputs": [],
   "source": [
    "# Resize images\n",
    "images32 = [transform.resize(image, (28, 28,3)) for image in images]\n",
    "images32 = np.array(images32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWUsMISHOrYt"
   },
   "outputs": [],
   "source": [
    "images32 = rgb2gray(np.array(images32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XM3XW-Z2ilO"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "images_flat = tf.contrib.layers.flatten(x)\n",
    "logits = tf.contrib.layers.fully_connected(images_flat, 100, tf.nn.relu)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "correct_pred = tf.argmax(logits, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "print(\"images_flat: \", images_flat)\n",
    "print(\"logits: \", logits)\n",
    "print(\"loss: \", loss)\n",
    "print(\"predicted_labels: \", correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXnRLZ1Q2y1s"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(201):\n",
    "        print('EPOCH', i)\n",
    "        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: images32, y: labels})\n",
    "        if i % 10 == 0:\n",
    "            print(\"Loss: \", loss)\n",
    "        print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhJS28Ex3ASu"
   },
   "outputs": [],
   "source": [
    "sample_indexes = random.sample(range(len(images32)), 10)\n",
    "sample_images = [images32[i] for i in sample_indexes]\n",
    "sample_labels = [labels[i] for i in sample_indexes]\n",
    "\n",
    "# Run the \"predicted_labels\" op.\n",
    "predicted = sess.run([correct_pred], feed_dict={x: sample_images})[0]\n",
    "                        \n",
    "# Print the real and predicted labels\n",
    "print(sample_labels)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vK3xBUZy3RKX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGM_Y3azyXn8"
   },
   "outputs": [],
   "source": [
    "# Display the predictions and the ground truth visually.\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(len(sample_images)):\n",
    "    truth = sample_labels[i]\n",
    "    prediction = predicted[i]\n",
    "    plt.subplot(5, 2,1+i)\n",
    "    plt.axis('off')\n",
    "    color='green' if truth == prediction else 'red'\n",
    "    plt.text(40, 10, \"Truth:        {0}\\nPrediction: {1}\".format(chr(truth), chr(prediction)), \n",
    "             fontsize=12, color=color)\n",
    "    plt.imshow(sample_images[i],cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FB_8Go0d3a_b"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
